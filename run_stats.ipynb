{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = os.getcwd()\n",
    "datapath = os.path.join(script_path,'data')\n",
    "resultpath = os.path.join(script_path,'results')\n",
    "most_likely = pd.read_csv(os.path.join(datapath,'most_likely.tsv'),delimiter='\\t',header=0)\n",
    "least_likely = pd.read_csv(os.path.join(datapath,'least_likely.tsv'),delimiter='\\t',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52528461",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load parameters into dictionaries\n",
    "resultsdict = {'most_likely':most_likely,'least_likely':least_likely}\n",
    "grouptype = {'selection_only':['selection'],'scope':['scope','selection'],\n",
    "             'domain':['domain','selection'],'round':['round','selection']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_stats(resultsdict,grouptype,resultopt,aggname,export='y'):\n",
    "    aggoption = grouptype[aggname]\n",
    "    results2test = resultsdict[resultopt]\n",
    "    tmpselect = results2test.groupby(aggoption)['participants'].sum().reset_index(name='total votes')\n",
    "    totals = tmpselect['total votes'].sum()\n",
    "    tmpselect['selection mean'] = tmpselect['total votes']/totals\n",
    "    tmpselect['per test mean'] = results2test.groupby(aggoption)['participants'].mean().tolist()\n",
    "    tmpselect['per test stdev'] = results2test.groupby(aggoption)['participants'].std().tolist()\n",
    "    tmpselect['per test stderr'] = results2test.groupby(aggoption)['participants'].sem().tolist()\n",
    "    tstamp = datetime.now()\n",
    "    sttstamp = tstamp.strftime(\"%Y-%m-%d\")\n",
    "    if export == 'y':\n",
    "        tmpselect.to_csv(os.path.join(resultpath,sttstamp+'_'+resultopt+'_'+aggname+'_basic_stats.tsv'),sep='\\t',header=True)\n",
    "    else:\n",
    "        return tmpselect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f02177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_basic_stats(resultsdict,grouptype,export='y'):\n",
    "    resultoptlist = list(resultsdict.keys())\n",
    "    aggnamelist = list(grouptype.keys())\n",
    "    for resultopt in resultoptlist:\n",
    "        for aggname in aggnamelist:\n",
    "            get_basic_stats(resultsdict,grouptype,resultopt,aggname,export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(results2test, aggopt, groupings):\n",
    "    tstamp = datetime.now()\n",
    "    sttstamp = tstamp.strftime(\"%Y-%m-%d\")\n",
    "    nonans = results2test['selection'].dropna()\n",
    "    combilist = nonans.unique().tolist()\n",
    "    selection_dict = {}\n",
    "    for eachselect in combilist:\n",
    "        selection_dict[eachselect] = np.array(results2test['participants'].loc[results2test['selection']==eachselect].tolist())\n",
    "    tmpresult = []\n",
    "    for combo in combinations(combilist, 2):  \n",
    "        a1 = selection_dict[combo[0]]\n",
    "        a2 = selection_dict[combo[1]]\n",
    "        if a1.mean() > a2.mean():\n",
    "            winner = combo[0]\n",
    "        else:\n",
    "            winner = combo[1]\n",
    "        tmpstat, tmp_p = stats.ttest_ind(a1, a2)\n",
    "        tmpdict = {\"function 1\":combo[0], \"function 2\":combo[1],\n",
    "                   \"mean 1\": a1.mean(), \"mean 2\": a2.mean(),\n",
    "                   \"stdev 1\": a1.std(), \"stdev 2\": a2.std(), \"winner\": winner,\n",
    "                   \"t-test\": tmpstat, \"p-val\": tmp_p, \"groupings\": groupings,\n",
    "                   \"aggregation approach\": aggopt, \"run-date\":sttstamp}\n",
    "        tmpresult.append(tmpdict)\n",
    "    return sttstamp, tmpresult\n",
    "\n",
    "def run_t_tests(resultsdict,grouptype,resultopt,aggopt,export='y'):\n",
    "    results2test = resultsdict[resultopt]\n",
    "    if aggopt == 'selection_only':\n",
    "        aggname = grouptype[aggopt]\n",
    "        groupings = \"None\"\n",
    "        sttstamp, tmpresult = compare_results(results2test, aggopt, groupings)\n",
    "    else: \n",
    "        testopts = results2test[aggopt].unique().tolist()\n",
    "        tmpresult = []\n",
    "        for eachopt in testopts:\n",
    "            tmpgroup = results2test.loc[results2test[aggopt]==eachopt]\n",
    "            groupings = eachopt\n",
    "            sttstamp, partialresult = compare_results(tmpgroup, aggopt, groupings)\n",
    "            tmpresult.extend(partialresult)\n",
    "    statisticsdf = pd.DataFrame(tmpresult)\n",
    "    print(statisticsdf.head(n=2))\n",
    "    if export == 'y':\n",
    "        statisticsdf.to_csv(os.path.join(resultpath,sttstamp+'_'+aggopt+'_'+resultopt+'.tsv'),sep='\\t',header=True)\n",
    "    else:\n",
    "        return statisticsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94c2f9",
   "metadata": {},
   "source": [
    "### Running the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get basic statistics (means, stdev, stderr, etc.)\n",
    "## Note, don't run this if you have no use for this data since it will generate lots of files\n",
    "run_all_basic_stats(resultsdict,grouptype,export='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run the T-tests\n",
    "\n",
    "#### No groupings, just compare selections\n",
    "## for most likely\n",
    "run_t_tests(resultsdict,grouptype,'most_likely','selection_only',export='y')\n",
    "## for least likely\n",
    "run_t_tests(resultsdict,grouptype,'least_likely','selection_only',export='y')\n",
    "\n",
    "#### Group by scope, compare selections\n",
    "## for most likely\n",
    "run_t_tests(resultsdict,grouptype,'most_likely','scope',export='y')\n",
    "## for least likely\n",
    "run_t_tests(resultsdict,grouptype,'least_likely','scope',export='y')\n",
    "\n",
    "#### Group by domain, compare selections\n",
    "## for most likely\n",
    "run_t_tests(resultsdict,grouptype,'most_likely','domain',export='y')\n",
    "## for least likely\n",
    "run_t_tests(resultsdict,grouptype,'least_likely','domain',export='y')\n",
    "\n",
    "#### Group by round, compare selections\n",
    "## for most likely\n",
    "run_t_tests(resultsdict,grouptype,'most_likely','round',export='y')\n",
    "## for least likely\n",
    "run_t_tests(resultsdict,grouptype,'least_likely','round',export='y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477eaf6",
   "metadata": {},
   "source": [
    "# Test components of the script\n",
    "\n",
    "These are various components of the previously defined modules. Ignore everything below here if the modules run fine. If the modules don't run, you can use this to troubleshoot different parts of the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now()\n",
    "print(tstamp.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Parts of the basic stats module\n",
    "## Get the Totals, Mean, Standard Deviation, Standard Error based on groupings by user selection\n",
    "resultopt = 'most_likely'\n",
    "aggopt = 'selection_only'\n",
    "aggname = grouptype[aggopt]\n",
    "results2test = resultsdict[resultopt]\n",
    "tmpselect = results2test.groupby(aggname)['participants'].sum().reset_index(name='total votes')\n",
    "totals = selection_only['total votes'].sum()\n",
    "print(totals)\n",
    "tmpselect['selection mean'] = tmpselect['total votes']/totals\n",
    "tmpselect['per test mean'] = results2test.groupby(grouptype['selection_only'])['participants'].mean().tolist()\n",
    "tmpselect['per test stdev'] = results2test.groupby(grouptype['selection_only'])['participants'].std().tolist()\n",
    "tmpselect['per test stderr'] = results2test.groupby(grouptype['selection_only'])['participants'].sem().tolist()\n",
    "print(tmpselect.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform single t-tests\n",
    "resultopt = 'most_likely'\n",
    "aggopt = 'selection_only'\n",
    "aggname = grouptype[aggopt]\n",
    "results2test = resultsdict[resultopt]\n",
    "\n",
    "c1 = np.array(results2test['participants'].loc[results2test['selection']=='c1'].tolist())\n",
    "c2 = np.array(results2test['participants'].loc[results2test['selection']=='c2'].tolist())\n",
    "c3 = np.array(results2test['participants'].loc[results2test['selection']=='c3'].tolist())\n",
    "c4 = np.array(results2test['participants'].loc[results2test['selection']=='c4'].tolist())\n",
    "\n",
    "print(\"c1 vs c2: \",stats.ttest_ind(c1, c2))\n",
    "print(\"c2 vs c3: \",stats.ttest_ind(c2, c3))\n",
    "print(\"c1 vs c3: \",stats.ttest_ind(c1, c3))\n",
    "print(\"c1 vs c4: \",stats.ttest_ind(c1, c4))\n",
    "print(\"c2 vs c4: \",stats.ttest_ind(c2, c4))\n",
    "print(\"c3 vs c4: \",stats.ttest_ind(c3, c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = stats.ttest_ind(c3, c4)\n",
    "print(len(c3), len(c4), statistic,pvalue)\n",
    "print(c3.mean(),c3.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c93f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Parts of the t-test comparison module\n",
    "\n",
    "## get the unique combis selected\n",
    "nonans = results2test['selection'].dropna()\n",
    "combilist = nonans.unique().tolist()\n",
    "print(combilist)\n",
    "\n",
    "## create a dictionary of the combis and the np arrays of the result dfs\n",
    "selection_dict = {}\n",
    "for eachselect in combilist:\n",
    "    selection_dict[eachselect] = np.array(results2test['participants'].loc[results2test['selection']==eachselect].tolist())\n",
    "\n",
    "## iterate through different combinations of the combis, run t-tests, and store the results\n",
    "tmpresult = []\n",
    "for combo in combinations(combilist, 2):  # 2 for pairs, 3 for triplets, etc\n",
    "    a1 = selection_dict[combo[0]]\n",
    "    a2 = selection_dict[combo[1]]\n",
    "    tmpstat, tmp_p = stats.ttest_ind(a1, a2)\n",
    "    tmpdict = {\"function 1\":combo[0], \"function 2\":combo[1],\n",
    "               \"mean 1\": a1.mean(), \"mean 2\": a2.mean(),\n",
    "               \"stdev 1\": a1.std(), \"stdev 2\": a2.std(),\n",
    "               \"t-test\": tmpstat, \"p-val\": tmp_p,\n",
    "               \"aggregation approach\": \"selection only\"}\n",
    "    tmpresult.append(tmpdict)\n",
    "\n",
    "statisticsdf = pd.DataFrame(tmpresult)\n",
    "print(statisticsdf.head(n=2))\n",
    "#statisticsdf.to_csv(os.path.join(resultpath,'user_choice_only_most.tsv'),sep='\\t',header=True)\n",
    "statisticsdf.to_csv(os.path.join(resultpath,'user_choice_only_least.tsv'),sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627a5c1",
   "metadata": {},
   "source": [
    "### Investigate effect of different groupings (domain or scope) on selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c71271",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the unique combis selected\n",
    "nonans = results2test['selection'].dropna()\n",
    "combilist = nonans.unique().tolist()\n",
    "print(combilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c49e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results2test['scope'].unique().tolist())\n",
    "print(results2test['domain'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scopeopts = ['very broad','broad','somewhat specific','very specific']\n",
    "scopeopts = results2test['scope'].unique().tolist()\n",
    "#domainopts = ['Infectious Disease', 'Allergy', 'Immunology', 'General Biomedical', 'Cell types', 'Experimental techniques']\n",
    "domainopts = results2test['domain'].unique().tolist()\n",
    "\n",
    "for eachopt in scopeopts:\n",
    "    tmpgroup = results2test.loc[results2test['scope']==eachopt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77214c7e",
   "metadata": {},
   "source": [
    "#### Subset the results by groupings, then run t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset and then perform t-tests\n",
    "tmpgroup = results2test.loc[results2test['scope']=='broad']\n",
    "tmpgroup2 = results2test.loc[results2test['scope']=='somewhat specific']\n",
    "c1_broad = np.array(tmpgroup['participants'].loc[tmpgroup['selection']=='c1'].tolist())\n",
    "c2_broad = np.array(tmpgroup['participants'].loc[tmpgroup['selection']=='c2'].tolist())\n",
    "c1_ss = np.array(tmpgroup2['participants'].loc[tmpgroup2['selection']=='c1'].tolist())\n",
    "c2_ss = np.array(tmpgroup2['participants'].loc[tmpgroup2['selection']=='c2'].tolist())\n",
    "print(\"broad terms, c1 vs c2: \",stats.ttest_ind(c1_broad, c2_broad))\n",
    "print(\"somewhat specific, c1 vs c2: \",stats.ttest_ind(c1_ss, c2_ss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a393f",
   "metadata": {},
   "source": [
    "#### Investigate doing paired t-test based on grouping rather than subsetting then running t-tests\n",
    "It's not clear paired t-tests are appropriate in this case, so this is not done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a746ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform paired t-test based on grouping\n",
    "tmpgroup = results2test.groupby(['selection','scope'])['participants'].sum().reset_index(name='votes')\n",
    "print(tmpgroup.head(n=2))\n",
    "c1_group = np.array(tmpgroup['votes'].loc[tmpgroup['selection']=='c1'].tolist())\n",
    "c2_group = np.array(tmpgroup['votes'].loc[tmpgroup['selection']=='c2'].tolist())\n",
    "## create arrays that follow a specific order to ensure proper pairing\n",
    "\n",
    "## Conduct paired t-test\n",
    "tmpstat,tmp_p = stats.ttest_rel(c1_group,c2_group)\n",
    "print(tmpstat,tmp_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9aec0",
   "metadata": {},
   "source": [
    "## Old Methods -- Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0374fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_t_tests(resultsdict,grouptype,resultopt,export='y'):\n",
    "    tstamp = datetime.now()\n",
    "    sttstamp = tstamp.strftime(\"%Y-%m-%d\")\n",
    "    aggopt = 'selection_only'\n",
    "    aggname = grouptype[aggopt]\n",
    "    results2test = resultsdict[resultopt]\n",
    "    nonans = results2test['selection'].dropna()\n",
    "    combilist = nonans.unique().tolist()\n",
    "    selection_dict = {}\n",
    "    for eachselect in combilist:\n",
    "        selection_dict[eachselect] = np.array(results2test['participants'].loc[results2test['selection']==eachselect].tolist())\n",
    "    tmpresult = []\n",
    "    for combo in combinations(combilist, 2):  \n",
    "        a1 = selection_dict[combo[0]]\n",
    "        a2 = selection_dict[combo[1]]\n",
    "        tmpstat, tmp_p = stats.ttest_ind(a1, a2)\n",
    "        tmpdict = {\"function 1\":combo[0], \"function 2\":combo[1],\n",
    "                   \"mean 1\": a1.mean(), \"mean 2\": a2.mean(),\n",
    "                   \"stdev 1\": a1.std(), \"stdev 2\": a2.std(),\n",
    "                   \"t-test\": tmpstat, \"p-val\": tmp_p,\n",
    "                   \"aggregation approach\": aggopt, \"run-date\":sttstamp}\n",
    "        tmpresult.append(tmpdict)\n",
    "\n",
    "    statisticsdf = pd.DataFrame(tmpresult)\n",
    "    print(statisticsdf.head(n=2))\n",
    "    if export == 'y':\n",
    "        statisticsdf.to_csv(os.path.join(resultpath,sttstamp+'_user_choice_only_'+resultopt+'.tsv'),sep='\\t',header=True)\n",
    "    else:\n",
    "        return statisticsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_t_tests(resultsdict,grouptype,'most_likely',export='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9edbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
